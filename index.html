<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chuanxia Zheng</title>

  <meta name="author" content="Chuanxia Zheng">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chuanxia Zheng</name>
              </p>
              <p>I am a research fellow in the <a href="https://research.monash.edu/en/organisations/department-of-data-science-ai"> Department of Data Science & AI </a> at <a href="https://www.monash.edu/">Monash University</a>, where I work on computer vision and machine learning with <a href="https://jianfei-cai.github.io/">Jianfei Cai</a> and <a href="https://research.monash.edu/en/persons/dinh-phung">Dinh Phung</a>.
              </p>
              <p>
                I received my PhD degree from the <a href="https://www.ntu.edu.sg/scse"> School of Computer Science and Engineering </a> at <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, where I was advised by <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a> and <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>. I was the winner of the <a href="https://www.ntu.edu.sg/scse/news-events/news/detail/scse-outstanding-phd-thesis-award-2022"> SCSE Outstanding PhD Thesis Award 2022</a>. Before that, I received the Masterâ€™s degree in the <a href="http://irmct.buaa.edu.cn/"> IR&MCT Lab </a> at Beihang University, advised by Jianhua Wang and <a href="http://dept3.buaa.edu.cn/szjs/zzjs/dgdzjxsyzx1/js/cwh.htm"> Weihai Chen</a>.
              </p>
              <p style="text-align:center">
                <a href="CHUANXIA001@e.ntu.edu.sg">Email</a> &nbsp/&nbsp
                <a href="data/cv_chuanxia.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=mvpE6bIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lyndonzheng">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/ChuanxiaZ">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <div class="news">
              <ul style="text-align:justify;height: 150px;">
              <li class="font"><font color="red">2022.09: Our paper <a target="_blank" href="">MoVQ</a> was accepted by NeurIPS2022.</font></li>
              <li class="font"><font color="red">2022.08: Our paper <a target="_blank" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0271056">Nuclear Predication</a> was accepted by PLOS ONE.</font></li>
              <li class="font">2022.07: Our paper <a target="_blank" href="https://wuqianyi.top/objectsdf/">ObjectSDF</a> and <a target="_blank" href="https://donydchen.github.io/sem2nerf/">Semantic2NeRF</a> were accepted by ECCV2022.</font></li>
              <li class="font">2022.06: I was the winner of the <a target="_blank" href="https://www.ntu.edu.sg/scse/news-events/news/detail/scse-outstanding-phd-thesis-award-2022">NTU Outstanding PhD Thesis Award 2022</a>.</font></li>
              <li class="font">2022.03: My thesis <a target="_blank" href="https://mp.weixin.qq.com/s/e1gqtDsH872sjfH4T4oL2w?scene=25#wechat_redirect">Synthesizing Photorealistic Scenes</a> was reported on media.</font></li>
              <li class="font">2022.03: Our paper <a target="_blank" href="https://chuanxiaz.com/tfill">TFill</a> was accepted by CVPR2022.</font></li>
              <li class="font">2021.08: Our paper <a target="_blank" href="https://chuanxiaz.com/vinv">Visiting the Invisible</a> was accepted by IJCV.</font></li>
              <li class="font">2021.07: One paper was accepted by ICCV2021.</font></li>
              <li class="font">2021.06: Our paper <a target="_blank" href="https://link.springer.com/article/10.1007/s11263-021-01502-7">Pluralistic Free-Form Image Completion </a> was accepted by IJCV.</font></li>
              <li class="font">2021.06: Our <a target="_blank" href="https://guoxiansong.github.io/homepage/agilegan.html">AgileGAN</a> was reported by <a target="_blank" href="https://www.sohu.com/a/471951100_629135">Sohu</a> and reproduced by <a target="_blank" href="https://github.com/open-mmlab/MMGEN-FaceStylor">Open MMLab</a>.</font></li>
              <li class="font">2021.04: Our paper <a target="_blank" href="https://guoxiansong.github.io/homepage/agilegan.html">AgileGAN</a> was accepted by SIGGRAPH2021.</font></li>
              <li class="font">2021.03: Our paper <a target="_blank" href="https://chuanxiaz.com/flsesim/">FLSeSim</a> was accepted by CVPR2021.</font></li>
              <li class="font">2019.03: Our paper <a target="_blank" href="https://chuanxiaz.com/pluralistic/">Pluralistic Image Completion</a> was accepted by CVPR2019.</font></li>
              <li class="font">2018.07: Our paper <a target="_blank" href='https://chuanxiaz.com/synthetic2real'>Synthetic2Real</a> was accepted by ECCV2018.</font></li>
              </ul>
              </div>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests are broadly in artificial intelligence, with emphasis on computer vision and machine learning. Much of my research is about image generation, completion and translation, 3D scene reconstruction, generation and completion with the goal of building intelligent machines, capable of rebuilding a photorealistic virtual world.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="objectsdf_stop()" onmouseover="objectsdf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='objectsdf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/objectsdf_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/objectsdf_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function objectsdf_start() {
                  document.getElementById('objectsdf_image').style.opacity = "1";
                }

                function objectsdf_stop() {
                  document.getElementById('objectsdf_image').style.opacity = "0";
                }
                objectsdf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://wuqianyi.top/objectsdf/">
                <papertitle>Object-Compositional Neural Implicit Surfaces</papertitle>
              </a>
              <br>
              <a href="https://wuqianyi.top/"> Qianyi Wu</a>,
              <a href="https://alvinliu0.github.io/"> Xian Liu</a>,
              <a href="https://donydchen.github.io/"> Yuedong Chen</a>,
              <a href="https://likojack.github.io/kejieli/#/home"> Kejie Li</a>,
              <strong>Chuanxia Zheng</strong>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <a href="https://personal.ntu.edu.sg/asjmzheng/">Jianmin Zheng</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://wuqianyi.top/objectsdf/">project page</a> /
              <a href="https://arxiv.org/abs/2207.09686">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=23vxOV19bEw">video</a> /
              <a href="https://github.com/QianyiWu/objsdf">code</a>
              <p></p>
              <p>Automatically decompose a scene into 3D instance, trained using only 2D semantic lables and images.</p>
            </td>
          </tr>

          <tr onmouseout="semantic2NeRF_stop()" onmouseover="semantic2NeRF_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='semantic2NeRF_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/semantic2NeRF_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/semantic2NeRF_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function semantic2NeRF_start() {
                  document.getElementById('semantic2NeRF_image').style.opacity = "1";
                }

                function semantic2NeRF_stop() {
                  document.getElementById('semantic2NeRF_image').style.opacity = "0";
                }
                semantic2NeRF_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://donydchen.github.io/sem2nerf/">
                <papertitle>Sem2NeRF: Converting Single-View Semantic Masks to Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://donydchen.github.io/"> Yuedong Chen</a>,
              <a href="https://wuqianyi.top/"> Qianyi Wu</a>,
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://donydchen.github.io/sem2nerf/">project page</a> /
              <a href="https://arxiv.org/abs/2203.10821">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=cYr3Dz8N_9E&feature=youtu.be">video</a> /
              <a href="https://github.com/donydchen/sem2nerf">code</a>
              <p></p>
              <p>We train a 3D inversion model to transfer the 2D semantic map into 3D NeRF, and lets users edit 3D model through 2D semantic input.</p>
            </td>
          </tr>

          <tr onmouseout="tfill_stop()" onmouseover="tfill_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tfill_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/tfill_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tfill_teaser.jpg' width="160">
              </div>
              <script type="text/javascript">
                function tfill_start() {
                  document.getElementById('tfill_image').style.opacity = "1";
                }

                function tfill_stop() {
                  document.getElementById('tfill_image').style.opacity = "0";
                }
                tfill_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://chuanxiaz.com/tfill">
                <papertitle>Bridging global context interactions for high-fidelity image completion</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <a href="https://research.monash.edu/en/persons/dinh-phung">Dinh Phung</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
							<a href="https://chuanxiaz.com/tfill">project page</a> /
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.pdf">PDF</a> /
							<a href="https://arxiv.org/abs/2104.00845">arXiv</a> /
							<a href="https://youtu.be/efB1fw0jiLs">video</a> /
							<a href="https://github.com/lyndonzheng/TFill">code</a> /
              <a href="data/2022CVPR_poster_TFill.pdf">poster</a>
              <p></p>
              <p>TFill fills in reasonable contents for both foreground object removal and content completion.</p>
            </td>
          </tr>

          <tr onmouseout="vinv_stop()" onmouseover="vinv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vinv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vinv_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vinv_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function vinv_start() {
                  document.getElementById('vinv_image').style.opacity = "1";
                }

                function vinv_stop() {
                  document.getElementById('vinv_image').style.opacity = "0";
                }
                vinv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chuanxiaz.com/vinv">
                <papertitle>Visiting the Invisible: Layer-by-Layer Completed Scene Decomposition</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://scholar.google.com/citations?user=AZWFq1sAAAAJ&hl=en">Duy-Son Dao</a>,
              <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <br>
              <em>IJCV</em>, 2021
              <br>
              <a href="https://chuanxiaz.com/vinv">project page</a> /
              <a href="https://link.springer.com/article/10.1007/s11263-021-01517-0">PDF</a> /
              <a href="https://arxiv.org/abs/2104.05367">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=QSAYxrKgn7A">video</a> /
              <a href="https://github.com/lyndonzheng/VINV">code</a>
              <p></p>
              <p>We build a high-level scene understanding system that simultaneously models the completed shape and appearance for all instances.</p>
            </td>
          </tr>


          <tr onmouseout="agilegan_stop()" onmouseover="agilegan_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='agilegan_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/agilegan_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/agilegan_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function agilegan_start() {
                  document.getElementById('agilegan_image').style.opacity = "1";
                }

                function agilegan_stop() {
                  document.getElementById('agilegan_image').style.opacity = "0";
                }
                agilegan_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://guoxiansong.github.io/homepage/agilegan.html">
                <papertitle>AgileGAN: Stylizing Portraits by Inversion-Consistent Transfer Learning</papertitle>
              </a>
              <br>
              <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>,
              <a href="http://linjieluo.com/">Linjie Luo</a>,
              <a href="https://www.jingliu.net/">Jing Liu</a>,
              <a href="https://en.wikipedia.org/wiki/Alex_Ma">Wan-Chun Ma</a>,
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <br>
              <em>SIGGRAPH</em>, 2021
              <br>
              <a href="https://guoxiansong.github.io/homepage/agilegan.html">project page</a> /
              <a href="https://guoxiansong.github.io/homepage/paper/AgileGAN.pdf">PDF</a> /
              <a href="https://www.youtube.com/embed/o0HHIvOT_n0">video</a> /
              <a href="https://github.com/GuoxianSong/AgileGAN">code</a> /
              <a href="http://www.agilegan.com/">Online Demo</a>
              <p></p>
              <p>A GAN inversion model is trained for Stylizing Portraits.</p>
            </td>
          </tr>


          <tr onmouseout="flsesim_stop()" onmouseover="flsesim_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flsesim_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/flsesim_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/flsesim_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function flsesim_start() {
                  document.getElementById('flsesim_image').style.opacity = "1";
                }
                function flsesim_stop() {
                  document.getElementById('flsesim_image').style.opacity = "0";
                }
                flsesim_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chuanxiaz.com/flsesim">
                <papertitle>The Spatially-Correlative Loss for Various Image Translation Tasks</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://chuanxiaz.com/flsesim">project page</a> /
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_The_Spatially-Correlative_Loss_for_Various_Image_Translation_Tasks_CVPR_2021_paper.pdf">PDF</a> /
              <a href="https://arxiv.org/abs/2104.00854">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=pu6PT1om2r0">video</a> /
              <a href="https://github.com/lyndonzheng/F-LSeSim">code</a> /
              <a href="data/2022CVPR_poster_TFill.pdf">poster</a>
              <p></p>
              <p>We propose a novel spatially-correlative loss that is simple, efficient and yet effective for preserving scene structure consistency while supporting large appearance changes during unpaired I2I translation.</p>
            </td>
          </tr>


          <tr onmouseout="pic_stop()" onmouseover="pic_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='pic_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/pic_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/pic_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function pic_start() {
                  document.getElementById('pic_image').style.opacity = "1";
                }
                function pic_stop() {
                  document.getElementById('pic_image').style.opacity = "0";
                }
                pic_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chuanxiaz.com/pic">
                <papertitle>Pluralistic (Free-Form) Image Completion</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>
              <br>
              <em>IJCV</em>, 2021
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://chuanxiaz.com/pic">project page</a> /
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Pluralistic_Image_Completion_CVPR_2019_paper.pdf">PDF</a> /
              <a href="https://arxiv.org/abs/1903.04227">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=9V7rNoLVmSs">video</a> /
              <a href="https://github.com/lyndonzheng/Pluralistic-Inpainting">code</a> /
              <a href="data/poster_picnet_cvpr19.pdf">poster</a>
              <p></p>
              <p>Given a single masked image, the proposed model is able to generate multiple and diverse plausible results.</p>
            </td>
          </tr>


          <tr onmouseout="synthetic2real_stop()" onmouseover="synthetic2real_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='synthetic2real_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/synthetic2real_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/synthetic2real_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function synthetic2real_start() {
                  document.getElementById('synthetic2real_image').style.opacity = "1";
                }
                function synthetic2real_stop() {
                  document.getElementById('synthetic2real_image').style.opacity = "0";
                }
                synthetic2real_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chuanxiaz.com/synthetic2real">
                <papertitle>T2Net: Synthetic-to-Realistic Translation for Depth Estimation Tasks</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>
              <br>
              <em>ECCV</em>, 2018
              <br>
              <a href="https://chuanxiaz.com/synthetic2real">project page</a> /
              <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Chuanxia_Zheng_T2Net_Synthetic-to-Realistic_Translation_ECCV_2018_paper.pdf">PDF</a> /
              <a href="https://arxiv.org/abs/1808.01454">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=B6lOToIk0xY">video</a> /
              <a href="https://github.com/lyndonzheng/Synthetic2Realistic">code</a> /
              <a href="data/poster_syn2real_eccv18.pdf">poster</a>
              <p></p>
              <p>Without any real depth map, the proposed model evaluates depth maps on real scenes using only synthetic datasets.</p>
            </td>
          </tr>

    </tbody></table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <heading>Academic Services</heading>
          <p><font size="4"><b>Conference Reviewer</b></font></p>
        <table>
          <tr>
            <td>CVPR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2020,&nbsp;2021,&nbsp;2022</td>
          </tr>
          <tr><td>ICCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2019,&nbsp;2021</td></tr>
          <tr><td>ECCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2020,&nbsp;2022</td></tr>
          <tr><td>ICLR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2021,&nbsp;2022,&nbsp;2023</td></tr>
          <tr><td>NeurIPS</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>SIGGRAPH&Asia</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>IJCAI</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>ACM MM</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2021,&nbsp;2022</td></tr>
          <tr><td>IROS</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
        </table>
          <p><font size="4"><b>Journal Reviewer</b></font></p>
          <p>TPAMI, IJCV, TIP, JAS, TMM(Outstanding Reviewer Award, 2021), TCSVT, CVIU, TVCJ, NCAA</p>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Teaching</heading>
          <ul style="text-align:justify;height: 00px;">
              <li class="font">Teaching Assistant, Advanced Digital Image Processing, Graduate, NTU, 2018-2020</font></li>
              <li class="font">Teaching Assistant, Human-Computer Interaction, Undergraduate, NTU, 2018-2020</font></li>
              <li class="font">Teaching Assistant, Engineering Mathematics, Undergraduate, NTU, 2018-2020</font></li>
          </ul>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              Yep it's another <a href="https://jonbarron.info">Jon Barron</a> website. <br>
              Last updated Sept. 2022.
          </font>
            </p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <script type="text/javascript" src="//ra.revolvermaps.com/0/0/1.js?i=0s5f0y0jjk8&amp;s=180&amp;m=6&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
            </td>
            </tr>
            </tbody></table>

      </td>
    </tr>
  </table>

  </body>
</html>
