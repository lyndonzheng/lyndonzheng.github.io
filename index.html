<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chuanxia Zheng</title>

  <meta name="author" content="Chuanxia Zheng">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chuanxia Zheng</name>
              </p>
              <p>I am a research fellow in the <a href="https://research.monash.edu/en/organisations/department-of-data-science-ai"> Department of Data Science & AI </a> at <a href="https://www.monash.edu/">Monash University</a>, where I work on computer vision and machine learning with <a href="https://jianfei-cai.github.io/">Jianfei Cai</a> and <a href="https://research.monash.edu/en/persons/dinh-phung">Dinh Phung</a>.
              </p>
              <p>
                I received my PhD degree from the <a href="https://www.ntu.edu.sg/scse"> School of Computer Science and Engineering </a> at <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, where I was advised by <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a> and <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>. I was the winner of the <a href="https://www.ntu.edu.sg/scse/news-events/news/detail/scse-outstanding-phd-thesis-award-2022"> SCSE Outstanding PhD Thesis Award 2022</a>. Before that, I received the Masterâ€™s degree in the <a href="http://irmct.buaa.edu.cn/"> IR&MCT Lab </a> at Beihang University, advised by Jianhua Wang and <a href="http://dept3.buaa.edu.cn/szjs/zzjs/dgdzjxsyzx1/js/cwh.htm"> Weihai Chen</a>.
              </p>
              <p style="text-align:center">
                <a href="CHUANXIA001@e.ntu.edu.sg">Email</a> &nbsp/&nbsp
                <a href="data/cv_chuanxia.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=mvpE6bIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lyndonzheng">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <div class="news">
              <ul style="text-align:justify;height: 150px;">
              <li class="font"><font color="red">2022.07: Our paper <a target="_blank" href="https://wuqianyi.top/objectsdf/">ObjectSDF</a> and <a target="_blank" href="https://donydchen.github.io/sem2nerf/">Semantic2NeRF</a> were accepted by ECCV2022.</font></li>
              <li class="font"><font color="red">2022.06: I was the winner of the <a target="_blank" href="https://www.ntu.edu.sg/scse/news-events/news/detail/scse-outstanding-phd-thesis-award-2022">NTU Outstanding PhD Thesis Award 2022</a>.</font></li>
              <li class="font">2022.03: My thesis <a target="_blank" href="https://mp.weixin.qq.com/s/e1gqtDsH872sjfH4T4oL2w?scene=25#wechat_redirect">Synthesizing Photorealistic Scenes</a> was reported on media.</font></li>
              <li class="font">2022.03: Our paper <a target="_blank" href="https://www.chuanxiaz.com/publication/TFill">TFill</a> was accepted by CVPR2022.</font></li>
              <li class="font">2021.08: Our paper <a target="_blank" href="https://www.chuanxiaz.com/publication/vinv">Visiting the Invisible</a> was accepted by IJCV.</font></li>
              <li class="font">2021.07: One paper was accepted by ICCV2021.</font></li>
              <li class="font">2021.06: Our paper <a target="_blank" href="https://link.springer.com/article/10.1007/s11263-021-01502-7">Pluralistic Free-Form Image Completion </a> was accepted by IJCV.</font></li>
              <li class="font">2021.06: Our <a target="_blank" href="https://guoxiansong.github.io/homepage/agilegan.html">AgileGAN</a> was reported by <a target="_blank" href="https://www.sohu.com/a/471951100_629135">Sohu</a> and reproduced by <a target="_blank" href="https://github.com/open-mmlab/MMGEN-FaceStylor">Open MMLab</a>.</font></li>
              <li class="font">2021.04: Our paper <a target="_blank" href="https://guoxiansong.github.io/homepage/agilegan.html">AgileGAN</a> was accepted by SIGGRAPH2021.</font></li>
              <li class="font">2021.03: Our paper <a target="_blank" href="https://www.chuanxiaz.com/publication/flsesim/">FLSeSim</a> was accepted by CVPR2021.</font></li>
              <li class="font">2019.03: Our paper <a target="_blank" href="https://www.chuanxiaz.com/publication/pluralistic/">Pluralistic Image Completion</a> was accepted by CVPR2019.</font></li>
              <li class="font">2018.07: Our paper <a target="_blank" href='https://www.chuanxiaz.com/publication/synthetic2real'>Synthetic2Real</a> was accepted by ECCV2018.</font></li>
              </ul>
              </div>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests are broadly in artificial intelligence, with emphasis on computer vision and machine learning. Much of my research is about image generation, completion and translation, 3D scene reconstruction, generation and completion with the goal of building intelligent machines, capable of rebuilding a virtually realistic world.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="objectsdf_stop()" onmouseover="objectsdf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='objectsdf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/objectsdf_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/objectsdf_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function objectsdf_start() {
                  document.getElementById('objectsdf_image').style.opacity = "1";
                }

                function objectsdf_stop() {
                  document.getElementById('objectsdf_image').style.opacity = "0";
                }
                objectsdf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://wuqianyi.top/objectsdf/">
                <papertitle>Object-Compositional Neural Implicit Surfaces</papertitle>
              </a>
              <br>
              <a href="https://wuqianyi.top/"> Qianyi Wu</a>,
              <a href="https://alvinliu0.github.io/"> Xian Liu</a>,
              <a href="https://donydchen.github.io/"> Yuedong Chen</a>,
              <a href="https://likojack.github.io/kejieli/#/home"> Kejie Li</a>,
              <strong>Chuanxia Zheng</strong>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <a href="https://personal.ntu.edu.sg/asjmzheng/">Jianmin Zheng</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://wuqianyi.top/objectsdf/">project page</a> /
              <a href="https://arxiv.org/abs/2207.09686">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=23vxOV19bEw">video</a> /
              <a href="https://github.com/QianyiWu/objsdf">code</a>
              <p></p>
              <p>Automatically decompose a scene into 3D instance, trained using only 2D semantic lables and images.</p>
            </td>
          </tr>

          <tr onmouseout="semantic2NeRF_stop()" onmouseover="semantic2NeRF_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='semantic2NeRF_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/semantic2NeRF_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/semantic2NeRF_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function semantic2NeRF_start() {
                  document.getElementById('semantic2NeRF_image').style.opacity = "1";
                }

                function semantic2NeRF_stop() {
                  document.getElementById('semantic2NeRF_image').style.opacity = "0";
                }
                semantic2NeRF_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://donydchen.github.io/sem2nerf/">
                <papertitle>Sem2NeRF: Converting Single-View Semantic Masks to Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://donydchen.github.io/"> Yuedong Chen</a>,
              <a href="https://wuqianyi.top/"> Qianyi Wu</a>,
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://donydchen.github.io/sem2nerf/">project page</a> /
              <a href="https://arxiv.org/abs/2203.10821">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=cYr3Dz8N_9E&feature=youtu.be">video</a> /
              <a href="https://github.com/donydchen/sem2nerf">code</a>
              <p></p>
              <p>We train a 3D inversion model to transfer the 2D semantic map into 3D NeRF, and lets users edit 3D model through 2D sementic input.</p>
            </td>
          </tr>

          <tr onmouseout="tfill_stop()" onmouseover="tfill_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tfill_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/tfill_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tfill_teaser.jpg' width="160">
              </div>
              <script type="text/javascript">
                function tfill_start() {
                  document.getElementById('tfill_image').style.opacity = "1";
                }

                function tfill_stop() {
                  document.getElementById('tfill_image').style.opacity = "0";
                }
                tfill_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.chuanxiaz.com/tfill">
                <papertitle>Bridging global context interactions for high-fidelity image completion</papertitle>
              </a>
              <br>
              <strong>Chuanxia Zheng</strong>,
              <a href="https://personal.ntu.edu.sg/astjcham/"> Tat-Jen Cham</a>,
              <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
              <a href="https://research.monash.edu/en/persons/dinh-phung">Dinh Phung</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
							<a href="https://www.chuanxiaz.com/tfill">project page</a> /
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.pdf">PDF</a> /
							<a href="https://arxiv.org/abs/2104.00845">arXiv</a> /
							<a href="https://youtu.be/efB1fw0jiLs">video</a> /
							<a href="https://github.com/lyndonzheng/TFill">code</a> /
              <a href="data/2022CVPR_poster_TFill.pdf">poster</a>
              <p></p>
              <p>TFill fills in reasonable contents for both foreground object removal and content completion.</p>
            </td>
          </tr>

    </tbody></table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <heading>Academic Services</heading>
          <p><font size="4"><b>Conference Reviewer</b></font></p>
        <table>
          <tr>
            <td>CVPR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2020,&nbsp;2021,&nbsp;2022</td>
          </tr>
          <tr><td>ICCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2019,&nbsp;2021</td></tr>
          <tr><td>ECCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2020,&nbsp;2022</td></tr>
          <tr><td>ICLR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2021,&nbsp;2022</td></tr>
          <tr><td>NeurIPS</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>IJCAI</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>SIGGRAPH&Asia</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
          <tr><td>ACM MM</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2021,&nbsp;2022</td></tr>
          <tr><td>IROS</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022</td></tr>
        </table>
          <p><font size="4"><b>Journal Reviewer</b></font></p>
          <p>TPAMI, IJCV, TIP, TMM(Outstanding Reviewer Award, 2021), TCSVT, CVIU, TVCJ, NCAA</p>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Teaching</heading>
          <ul style="text-align:justify;height: 00px;">
              <li class="font">Teaching Assistant, Advanced Digital Image Processing, Graduate, NTU, 2018-2020</font></li>
              <li class="font">Teaching Assistant, Human-Computer Interaction, Undergraduate, NTU, 2018-2020</font></li>
              <li class="font">Teaching Assistant, Engineering Mathematics, Undergraduate, NTU, 2018-2020</font></li>
          </ul>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              Yep it's another <a href="https://jonbarron.info">Jon Barron</a> website. <br>
              Last updated July 2022.
          </font>
            </p>
            </td>
          </tr>
        </table>

        <script type="text/javascript" src="//ra.revolvermaps.com/0/0/1.js?i=0s5f0y0jjk8&amp;s=180&amp;m=6&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>

      </td>
    </tr>
  </table>

  </body>
</html>
